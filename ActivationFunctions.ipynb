{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "black-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import elu,exponential,gelu,linear,relu,selu,sigmoid,softmax,softplus,swish,tanh\n",
    "from tensorflow.math import add,atan,cos,erf,maximum,minimum,sin,sqrt,subtract\n",
    "from deap.gp import PrimitiveSet,PrimitiveTree,genGrow,genFull,compile,cxOnePoint,mutShrink,staticLimit\n",
    "from deap.algorithms import eaSimple\n",
    "from deap import creator,base,tools \n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import operator \n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-beaver",
   "metadata": {},
   "source": [
    "# We define the Evolutionary Algorithm class, which encapsulates everything that has to do with the evolution. This class has access to a LangevinEBM object, which implements a function that trains an EBM using Langevin Dynamics and the other bells and whistles found in the OpenAI paper, and then returns a scalar score that is directly proportional to the fitness of an individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "apparent-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolutionaryAlgorithm:\n",
    "    \n",
    "    def __init__(self,base_act_functions,base_operations,min_depth,max_depth,pop_size):\n",
    "        \n",
    "        # We first initialize the pset that contains our base \n",
    "        # building blocks.\n",
    "        \n",
    "        self.base_act_functions=base_act_functions\n",
    "        self.base_operations=base_operations\n",
    "        self.pset=self.initialize_pset(base_act_functions,base_operations)\n",
    "        self.pop_size=pop_size \n",
    "        \n",
    "        # We specify that we are dealing with a maximization problem, and \n",
    "        # that our individual is a PrimitiveTree. We add a reference \n",
    "        # to the pset in \"Individual\", since it is used by some DEAP \n",
    "        # GP operators when modifying an individual.\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\",PrimitiveTree,fitness=creator.FitnessMax,pset=self.pset)\n",
    "        \n",
    "        self.toolbox=base.Toolbox()\n",
    "        \n",
    "        # Our toolbox contains an \"expr\" function that calls genGrow with \n",
    "        # the pset as a parameter. genGrow also takes as parameter the \n",
    "        # minimum and maximum depth of the tree. We do not fix them\n",
    "        # here, and we leave them as variables which can be changed when \n",
    "        # creating a population with the create_generation() function\n",
    "        \n",
    "        self.toolbox.register(\"expr\",genGrow,pset=self.pset,min_=min_depth,max_=max_depth)\n",
    "        \n",
    "        #The \"individual\" function calls \"expr()\" on a \"creator.Individual\" object \n",
    "        # and returns it. In other words, it simply creates a new Primitive tree \n",
    "        # from our pset\n",
    "        self.toolbox.register(\"individual\",tools.initIterate,creator.Individual,self.toolbox.expr)\n",
    "        \n",
    "        # We register the variation operators and a simple EA algorithm.\n",
    "        \n",
    "        self.toolbox.register(\"evaluate\",self.get_ebm_fitness)\n",
    "        self.toolbox.register(\"select\",tools.selRoulette)\n",
    "        self.toolbox.register(\"mate\",cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\",mutShrink)\n",
    "        \n",
    "        # We decorate the mating and mutation operator with a limit on the maximum depth.\n",
    "        \n",
    "        self.toolbox.decorate(\"mate\",staticLimit(key=operator.attrgetter(\"height\"),max_value=5))\n",
    "        self.toolbox.decorate(\"mutate\",staticLimit(key=operator.attrgetter(\"height\"),max_value=5))\n",
    "        \n",
    "        stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats_size = tools.Statistics(len)\n",
    "        self.mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "        self.mstats.register(\"avg\", np.mean)\n",
    "        self.mstats.register(\"std\", np.std)\n",
    "        self.mstats.register(\"min\", np.min)\n",
    "        self.mstats.register(\"max\", np.max)\n",
    "        \n",
    "        # We also add a Hall of fame object, and we keep the 10 best individuals in it.\n",
    "        \n",
    "        self.hof=tools.HallOfFame(10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def initialize_pset(self,base_act_functions,base_operations):\n",
    "        \n",
    "        # Our desired functions are unary and we specificy this when creating the pset\n",
    "        pset=PrimitiveSet(\"main\",1)\n",
    "        \n",
    "        # Activation functions in a neural network have \n",
    "        # arity 1.\n",
    "        for func in base_act_functions:\n",
    "            pset.addPrimitive(func,1)\n",
    "            \n",
    "        # The operations that we are considering, such as \n",
    "        # maximum, add or subtract, have arity 2.\n",
    "        for op in base_operations:\n",
    "            pset.addPrimitive(op,2)\n",
    "            \n",
    "        pset.renameArguments(ARG0=\"x\")\n",
    "        \n",
    "        return pset\n",
    "\n",
    "    def adjust_activation_tree(self,activation_tree):\n",
    "        copied_activation_tree = deepcopy(activation_tree)\n",
    "        bias_pset = PrimitiveSet(name='bias_set', arity=1)\n",
    "        for func in self.base_act_functions:\n",
    "            bias_pset.addTerminal(terminal=func, name='terminal_' + func.__name__)\n",
    "        for func in self.base_act_functions:\n",
    "            bias_pset.addPrimitive(primitive=func, arity=1, name=func.__name__)\n",
    "        primitives_dictionary = {}\n",
    "        for bias_primitive in bias_pset.primitives[object]:\n",
    "            for primitive in self.pset.primitives[object]:\n",
    "                if bias_primitive.name == primitive.name:\n",
    "                    primitives_dictionary[bias_primitive.name] = primitive\n",
    "        tree_elements = np.vectorize(lambda x: x.name)\n",
    "        num_terminals = Counter(tree_elements(copied_activation_tree))['ARG0']\n",
    "        starting_index = 0\n",
    "        two_literals = False\n",
    "        for i in range(num_terminals):\n",
    "            done = False\n",
    "            while not done:\n",
    "                bias_activation = PrimitiveTree(genFull(pset=bias_pset, min_=1, max_=1))\n",
    "                if 'ARG0' not in tree_elements(bias_activation):\n",
    "                    done = True\n",
    "            for i in range(starting_index, len(copied_activation_tree)):\n",
    "                if i < len(copied_activation_tree) - 1:\n",
    "                    condition = copied_activation_tree[i].name == 'ARG0' and \\\n",
    "                                (copied_activation_tree[i + 1].name == 'ARG0' or two_literals)\n",
    "                else:\n",
    "                    condition = copied_activation_tree[i].name == 'ARG0' and two_literals\n",
    "                if condition:\n",
    "                    if i < len(copied_activation_tree) - 1:\n",
    "                        two_literals = copied_activation_tree[i + 1].name == 'ARG0'\n",
    "                    replace_by_activation = np.random.choice([True, False], p=[0.8, 0.2])\n",
    "                    if replace_by_activation:\n",
    "                        starting_index = i + 2\n",
    "                        activation_primitive = primitives_dictionary[bias_activation[0].name]\n",
    "                        copied_activation_tree.insert(i, activation_primitive)\n",
    "                    else:\n",
    "                        starting_index = i + 1\n",
    "                    break\n",
    "        return copied_activation_tree\n",
    "    \n",
    "    def create_generation(self):\n",
    "        generation=[self.toolbox.individual() for i in range(self.pop_size)]\n",
    "        generation=[self.adjust_activation_tree(x) for x in generation]\n",
    "        return generation\n",
    "    \n",
    "    # This will be replaced with a proper EBM training function later on. Make sure to take care of nan case \n",
    "    \n",
    "    def get_ebm_fitness(self,individual):\n",
    "        \n",
    "        # Choose some very bad value in case of an error, not infinity to prevent DEAP from encountering an error\n",
    "        f=compile(individual,self.pset)\n",
    "        const=tf.constant([1.0,2.0,3.0])\n",
    "        fitness=np.around(tf.reduce_sum(f(const)).numpy(),2)\n",
    "        if np.isnan(fitness) or np.isinf(fitness):\n",
    "            fitness= -10**3\n",
    "        return (fitness,)\n",
    "    \n",
    "    def evolve_functions(self,num_generations):\n",
    "        pop=self.create_generation()\n",
    "        pop,log=eaSimple(pop,self.toolbox,ngen=num_generations,cxpb=0.8,mutpb=0.02,stats=self.mstats,halloffame=self.hof,verbose=True)\n",
    "        return pop\n",
    "    \n",
    "    def get_hof_inds(self):\n",
    "        return ['Function:{}\\tFitness:{}'.format(str(mvp),mvp.fitness.values[0]) for mvp in self.hof]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divided-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_functions=[elu,gelu,linear,relu,selu,sigmoid,softplus,swish,tanh,atan,cos,erf,sin,sqrt]\n",
    "base_operations=[maximum,minimum,add,subtract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "potential-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/andy/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "evo=EvolutionaryAlgorithm(base_functions,base_operations,min_depth=1,max_depth=3,pop_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polyphonic-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#individuals=evo.create_generation()\n",
    "#for ind in individuals:\n",
    "#    print(str(ind))\n",
    "#for ind in individuals:\n",
    "#    print(evo.get_ebm_fitness(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sustainable-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                    fitness                    \t                      size                     \n",
      "   \t      \t-----------------------------------------------\t-----------------------------------------------\n",
      "gen\tnevals\tavg  \tgen\tmax \tmin \tnevals\tstd    \tavg\tgen\tmax\tmin\tnevals\tstd    \n",
      "0  \t10    \t4.427\t0  \t9.61\t2.16\t10    \t2.18193\t3.4\t0  \t7  \t2  \t10    \t1.68523\n",
      "1  \t6     \t5.054\t1  \t9.61\t2.56\t6     \t2.11892\t3.2\t1  \t7  \t2  \t6     \t1.72047\n",
      "2  \t8     \t5.246\t2  \t9.61\t2.14\t8     \t2.19194\t3.2\t2  \t7  \t2  \t8     \t1.72047\n",
      "3  \t8     \t6.691\t3  \t12.61\t3.14\t8     \t2.8229 \t3.9\t3  \t8  \t2  \t8     \t1.92094\n",
      "4  \t6     \t8.476\t4  \t12.61\t3.14\t6     \t2.83517\t4.5\t4  \t6  \t2  \t6     \t1.28452\n",
      "5  \t8     \t8.636\t5  \t12.61\t6   \t8     \t2.71782\t4.5\t5  \t6  \t2  \t8     \t1.68819\n",
      "6  \t6     \t8.859\t6  \t12.61\t3.14\t6     \t2.85744\t4.9\t6  \t6  \t2  \t6     \t1.3    \n",
      "7  \t6     \t10.491\t7  \t12.61\t6   \t6     \t2.46412\t5.5\t7  \t8  \t2  \t6     \t1.56525\n",
      "8  \t8     \t11.602\t8  \t12.61\t9.14\t8     \t1.13205\t5.2\t8  \t8  \t4  \t8     \t1.4    \n",
      "9  \t8     \t11.827\t9  \t12.61\t9.66\t8     \t0.744877\t4.6\t9  \t8  \t4  \t8     \t1.28062\n",
      "10 \t8     \t11.794\t10 \t18   \t6   \t8     \t3.08367 \t4.8\t10 \t8  \t2  \t8     \t1.66132\n",
      "\n",
      "\n",
      "\n",
      "Function:relu(add(x, add(x, x)))\tFitness:18.0\n",
      "Function:relu(add(add(atan(x), x), x))\tFitness:15.140000343322754\n",
      "Function:selu(relu(add(x, x)))\tFitness:12.609999656677246\n",
      "Function:selu(relu(add(x, elu(x))))\tFitness:12.609999656677246\n",
      "Function:relu(add(x, x))\tFitness:12.0\n",
      "Function:relu(relu(add(x, x)))\tFitness:12.0\n",
      "Function:relu(relu(add(elu(x), elu(x))))\tFitness:12.0\n",
      "Function:relu(relu(add(x, elu(x))))\tFitness:12.0\n",
      "Function:relu(add(x, elu(x)))\tFitness:12.0\n",
      "Function:relu(add(atan(add(atan(x), x)), x))\tFitness:9.65999984741211\n"
     ]
    }
   ],
   "source": [
    "pop=evo.evolve_functions(10)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "hof_info=evo.get_hof_inds()\n",
    "for mvp_info in hof_info:\n",
    "    print(mvp_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-boards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-trout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-class",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-vintage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-oracle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gothic-abortion",
   "metadata": {},
   "source": [
    "# Abhishek: What I expect from you:\n",
    "\n",
    "# 1) Define an EBM class that has a get_ebm_fitness(activation_function,train_test,val_test) function that returns a scalar directly proportional to the goodness.\n",
    "# 2) Potential example of such a class\n",
    "# 3) Be very careful about compatibility issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBMProbML:\n",
    "    \n",
    "    def train_ebm(self,mode,activation_function=tf.keras.activations.relu,train_set,val_set):\n",
    "        # It returns a scalar value that is DIRECTLY PROPORTIONAL to the \"goodness\"\n",
    "        # Train on train set, evaluate on validation set.\n",
    "        # All of these modes and their measure of fitness are described in the main paper\n",
    "        if mode=='unconditional':\n",
    "            return train_cifar10_unconditional(...)\n",
    "        elif mode=='condtional':\n",
    "            return train_cifar10_conditional(...)\n",
    "        elif mode=='train_ood':\n",
    "            return train_ood(...)\n",
    "        \n",
    "    def train_cifar10_unconditional(self,...):\n",
    "        return fitness\n",
    "    \n",
    "    def train_cifar10_conditional(self,...):\n",
    "        return fitness\n",
    "    \n",
    "    def train_ood(self,...):\n",
    "        return fitness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
